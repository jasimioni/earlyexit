{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d29764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from models.AlexNet import AlexNetMNIST, AlexNetMNISTee1, AlexNetMNISTee2\n",
    "from models.Branchynet import Branchynet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649c2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783d9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "batch_size = 600\n",
    "\n",
    "train_data   = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "test_data    = datasets.FashionMNIST(root='../data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef74b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNetMNIST(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AlexNetMNIST().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ac6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    break\n",
    "\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)\n",
    "x = model.layer1(x)\n",
    "print(x.shape)\n",
    "x = model.layer2(x)\n",
    "print(x.shape)\n",
    "x = model.layer3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84c5ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:    1 [   600/60000]  loss: 2.34583187  accuracy train:  10.667%\n",
      "epoch:  0  batch:   11 [  6600/60000]  loss: 1.41046405  accuracy train:  29.318%\n",
      "epoch:  0  batch:   21 [ 12600/60000]  loss: 0.93356800  accuracy train:  43.921%\n",
      "epoch:  0  batch:   31 [ 18600/60000]  loss: 0.76334333  accuracy train:  52.134%\n",
      "epoch:  0  batch:   41 [ 24600/60000]  loss: 0.73419976  accuracy train:  57.114%\n",
      "epoch:  0  batch:   51 [ 30600/60000]  loss: 0.57557380  accuracy train:  60.624%\n",
      "epoch:  0  batch:   61 [ 36600/60000]  loss: 0.56638235  accuracy train:  63.232%\n",
      "epoch:  0  batch:   71 [ 42600/60000]  loss: 0.53182906  accuracy train:  65.322%\n",
      "epoch:  0  batch:   81 [ 48600/60000]  loss: 0.53560692  accuracy train:  67.082%\n",
      "epoch:  0  batch:   91 [ 54600/60000]  loss: 0.48125726  accuracy train:  68.522%\n",
      "Accuracy test: 80.02%\n",
      "epoch:  1  batch:    1 [   600/60000]  loss: 0.58004326  accuracy train:  78.667%\n",
      "epoch:  1  batch:   11 [  6600/60000]  loss: 0.44685999  accuracy train:  81.167%\n",
      "epoch:  1  batch:   21 [ 12600/60000]  loss: 0.43213475  accuracy train:  81.905%\n",
      "epoch:  1  batch:   31 [ 18600/60000]  loss: 0.50008529  accuracy train:  82.247%\n",
      "epoch:  1  batch:   41 [ 24600/60000]  loss: 0.41049424  accuracy train:  82.821%\n",
      "epoch:  1  batch:   51 [ 30600/60000]  loss: 0.41670302  accuracy train:  83.160%\n",
      "epoch:  1  batch:   61 [ 36600/60000]  loss: 0.37977627  accuracy train:  83.377%\n",
      "epoch:  1  batch:   71 [ 42600/60000]  loss: 0.45504192  accuracy train:  83.570%\n",
      "epoch:  1  batch:   81 [ 48600/60000]  loss: 0.36581042  accuracy train:  83.895%\n",
      "epoch:  1  batch:   91 [ 54600/60000]  loss: 0.32592937  accuracy train:  84.128%\n",
      "Accuracy test: 85.92%\n",
      "epoch:  2  batch:    1 [   600/60000]  loss: 0.36139104  accuracy train:  87.833%\n",
      "epoch:  2  batch:   11 [  6600/60000]  loss: 0.36413607  accuracy train:  86.894%\n",
      "epoch:  2  batch:   21 [ 12600/60000]  loss: 0.30895281  accuracy train:  86.937%\n",
      "epoch:  2  batch:   31 [ 18600/60000]  loss: 0.25396019  accuracy train:  87.086%\n",
      "epoch:  2  batch:   41 [ 24600/60000]  loss: 0.34787536  accuracy train:  87.008%\n",
      "epoch:  2  batch:   51 [ 30600/60000]  loss: 0.35171655  accuracy train:  87.023%\n",
      "epoch:  2  batch:   61 [ 36600/60000]  loss: 0.41748106  accuracy train:  87.085%\n",
      "epoch:  2  batch:   71 [ 42600/60000]  loss: 0.32731551  accuracy train:  87.138%\n",
      "epoch:  2  batch:   81 [ 48600/60000]  loss: 0.39868414  accuracy train:  87.218%\n",
      "epoch:  2  batch:   91 [ 54600/60000]  loss: 0.34485516  accuracy train:  87.304%\n",
      "Accuracy test: 87.41%\n",
      "epoch:  3  batch:    1 [   600/60000]  loss: 0.26137078  accuracy train:  90.667%\n",
      "epoch:  3  batch:   11 [  6600/60000]  loss: 0.31255248  accuracy train:  88.788%\n",
      "epoch:  3  batch:   21 [ 12600/60000]  loss: 0.29368412  accuracy train:  88.921%\n",
      "epoch:  3  batch:   31 [ 18600/60000]  loss: 0.35585764  accuracy train:  88.699%\n",
      "epoch:  3  batch:   41 [ 24600/60000]  loss: 0.34680215  accuracy train:  88.728%\n",
      "epoch:  3  batch:   51 [ 30600/60000]  loss: 0.30489281  accuracy train:  88.641%\n",
      "epoch:  3  batch:   61 [ 36600/60000]  loss: 0.32986963  accuracy train:  88.724%\n",
      "epoch:  3  batch:   71 [ 42600/60000]  loss: 0.33954769  accuracy train:  88.829%\n",
      "epoch:  3  batch:   81 [ 48600/60000]  loss: 0.28705350  accuracy train:  88.842%\n",
      "epoch:  3  batch:   91 [ 54600/60000]  loss: 0.28804886  accuracy train:  88.908%\n",
      "Accuracy test: 87.92%\n",
      "epoch:  4  batch:    1 [   600/60000]  loss: 0.27905348  accuracy train:  90.167%\n",
      "epoch:  4  batch:   11 [  6600/60000]  loss: 0.30311221  accuracy train:  88.697%\n",
      "epoch:  4  batch:   21 [ 12600/60000]  loss: 0.31182060  accuracy train:  88.802%\n",
      "epoch:  4  batch:   31 [ 18600/60000]  loss: 0.28864262  accuracy train:  88.833%\n",
      "epoch:  4  batch:   41 [ 24600/60000]  loss: 0.26721323  accuracy train:  89.195%\n",
      "epoch:  4  batch:   51 [ 30600/60000]  loss: 0.30478117  accuracy train:  89.235%\n",
      "epoch:  4  batch:   61 [ 36600/60000]  loss: 0.25234121  accuracy train:  89.287%\n",
      "epoch:  4  batch:   71 [ 42600/60000]  loss: 0.27739024  accuracy train:  89.331%\n",
      "epoch:  4  batch:   81 [ 48600/60000]  loss: 0.29735813  accuracy train:  89.397%\n",
      "epoch:  4  batch:   91 [ 54600/60000]  loss: 0.24603701  accuracy train:  89.449%\n",
      "Accuracy test: 89.30%\n",
      "\n",
      "Duration: 162 seconds\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    tst_cnt  = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        b += 1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if (b-1)%10 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{batch_size*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy train: {trn_corr.item()*100/(batch_size*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            tst_cnt  += len(predicted)\n",
    "\n",
    "    print(f\"Accuracy test: {100*tst_corr/tst_cnt:2.2f}%\")\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1419254f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nome' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mnome\u001b[49m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoao\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m }\n\u001b[1;32m      4\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnome\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nome' is not defined"
     ]
    }
   ],
   "source": [
    "x = {\n",
    "    nome: \"Joao\"\n",
    "}\n",
    "x['nome']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
