{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F          # adds some efficiency\n",
    "from torch.utils.data import DataLoader  # lets us load data in batches\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix  # for evaluating results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([938330, 48])\n",
      "torch.Size([938330])\n",
      "torch.Size([938330, 48])\n",
      "torch.Size([938330])\n"
     ]
    }
   ],
   "source": [
    "train_data   = CustomMawiDataset(year='2019', month='01', as_matrix=False)\n",
    "test_data    = CustomMawiDataset(year='2019', month='01', as_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1., 74., 74.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., 74.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)  # for consistent results\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "970\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3060\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3854\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "4232\n",
      "(5000, 48)\n",
      "1377\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3225\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1564\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "4954\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3528\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3485\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "4502\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "457\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "4584\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "756\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3904\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3802\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3492\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2470\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1568\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "793\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1846\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "1824\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "4506\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3826\n",
      "(5000, 48)\n",
      "2842\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3938\n",
      "(5000, 48)\n",
      "4282\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3741\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3236\n",
      "(5000, 48)\n",
      "355\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1054\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3516\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1914\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2907\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "2272\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2385\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "2958\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2150\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "2742\n",
      "(5000, 48)\n",
      "1800\n",
      "(5000, 48)\n",
      "3658\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2694\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "954\n",
      "(5000, 48)\n",
      "3666\n",
      "(5000, 48)\n",
      "1714\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "2193\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "3900\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "3306\n",
      "(5000, 48)\n",
      "4488\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "1848\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "5000\n",
      "(5000, 48)\n",
      "1816\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "0\n",
      "(5000, 48)\n",
      "4927\n",
      "(5000, 48)\n",
      "5000\n",
      "(3330, 48)\n",
      "3330\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(test_loader):\n",
    "    print(X.numpy().shape)\n",
    "    y_np = y.numpy()\n",
    "    print(np.count_nonzero(y_np == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_sz=48, out_sz=2, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_sz,layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0],layers[1])\n",
    "        self.fc3 = nn.Linear(layers[1],out_sz)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilayerPerceptron(\n",
       "  (fc1): Linear(in_features=48, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "model = MultilayerPerceptron()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  200 [ 20000/60000]  loss: 85.29566193  accuracy:  51.650%\n",
      "epoch:  0  batch:  400 [ 40000/60000]  loss: 177.84921265  accuracy:  53.483%\n",
      "epoch:  0  batch:  600 [ 60000/60000]  loss: 547.72784424  accuracy:  55.185%\n",
      "epoch:  0  batch:  800 [ 80000/60000]  loss: 122.79354858  accuracy:  55.657%\n",
      "epoch:  0  batch: 1000 [100000/60000]  loss: 5.57355785  accuracy:  55.999%\n",
      "epoch:  0  batch: 1200 [120000/60000]  loss: 35.77248383  accuracy:  56.839%\n",
      "epoch:  0  batch: 1400 [140000/60000]  loss: 15.87997341  accuracy:  57.657%\n",
      "epoch:  0  batch: 1600 [160000/60000]  loss: 37.67325592  accuracy:  58.956%\n",
      "epoch:  0  batch: 1800 [180000/60000]  loss: 2.24359465  accuracy:  59.545%\n",
      "epoch:  0  batch: 2000 [200000/60000]  loss: 4.90122843  accuracy:  60.423%\n",
      "epoch:  0  batch: 2200 [220000/60000]  loss: 41.68755341  accuracy:  61.120%\n",
      "epoch:  0  batch: 2400 [240000/60000]  loss: 26.38664055  accuracy:  61.667%\n",
      "epoch:  0  batch: 2600 [260000/60000]  loss: 2.38094020  accuracy:  62.425%\n",
      "epoch:  0  batch: 2800 [280000/60000]  loss: 22.55840302  accuracy:  63.201%\n",
      "epoch:  0  batch: 3000 [300000/60000]  loss: 2.08035135  accuracy:  63.758%\n",
      "epoch:  0  batch: 3200 [320000/60000]  loss: 13.87826824  accuracy:  64.417%\n",
      "epoch:  0  batch: 3400 [340000/60000]  loss: 4.30368710  accuracy:  64.914%\n",
      "epoch:  0  batch: 3600 [360000/60000]  loss: 8.24818230  accuracy:  65.431%\n",
      "epoch:  0  batch: 3800 [380000/60000]  loss: 0.58736235  accuracy:  65.902%\n",
      "epoch:  0  batch: 4000 [400000/60000]  loss: 2.60222507  accuracy:  66.374%\n",
      "epoch:  0  batch: 4200 [420000/60000]  loss: 3.04562259  accuracy:  66.649%\n",
      "epoch:  0  batch: 4400 [440000/60000]  loss: 14.25961685  accuracy:  66.861%\n",
      "epoch:  0  batch: 4600 [460000/60000]  loss: 4.13351202  accuracy:  67.193%\n",
      "epoch:  0  batch: 4800 [480000/60000]  loss: 8.12994194  accuracy:  67.510%\n",
      "epoch:  0  batch: 5000 [500000/60000]  loss: 0.66068304  accuracy:  67.852%\n",
      "epoch:  0  batch: 5200 [520000/60000]  loss: 0.56794524  accuracy:  68.169%\n",
      "epoch:  0  batch: 5400 [540000/60000]  loss: 0.60516143  accuracy:  68.454%\n",
      "epoch:  0  batch: 5600 [560000/60000]  loss: 0.98744559  accuracy:  68.758%\n",
      "epoch:  0  batch: 5800 [580000/60000]  loss: 0.87412190  accuracy:  68.895%\n",
      "epoch:  0  batch: 6000 [600000/60000]  loss: 0.70466322  accuracy:  69.033%\n",
      "epoch:  0  batch: 6200 [620000/60000]  loss: 2.27406621  accuracy:  69.307%\n",
      "epoch:  0  batch: 6400 [640000/60000]  loss: 0.42663449  accuracy:  69.620%\n",
      "epoch:  0  batch: 6600 [660000/60000]  loss: 3.43898439  accuracy:  69.896%\n",
      "epoch:  0  batch: 6800 [680000/60000]  loss: 1.19632816  accuracy:  70.134%\n",
      "epoch:  0  batch: 7000 [700000/60000]  loss: 0.53719532  accuracy:  70.381%\n",
      "epoch:  0  batch: 7200 [720000/60000]  loss: 0.47543848  accuracy:  70.668%\n",
      "epoch:  0  batch: 7400 [740000/60000]  loss: 0.41962683  accuracy:  70.897%\n",
      "epoch:  0  batch: 7600 [760000/60000]  loss: 0.39584264  accuracy:  71.164%\n",
      "epoch:  0  batch: 7800 [780000/60000]  loss: 0.48729515  accuracy:  71.415%\n",
      "epoch:  0  batch: 8000 [800000/60000]  loss: 0.51135814  accuracy:  71.648%\n",
      "epoch:  0  batch: 8200 [820000/60000]  loss: 0.42366055  accuracy:  71.875%\n",
      "epoch:  0  batch: 8400 [840000/60000]  loss: 0.50410378  accuracy:  72.100%\n",
      "epoch:  0  batch: 8600 [860000/60000]  loss: 18.69184494  accuracy:  72.219%\n",
      "epoch:  0  batch: 8800 [880000/60000]  loss: 0.43258512  accuracy:  72.347%\n",
      "epoch:  0  batch: 9000 [900000/60000]  loss: 0.42621547  accuracy:  72.518%\n",
      "epoch:  0  batch: 9200 [920000/60000]  loss: 0.47197545  accuracy:  72.677%\n",
      "epoch:  1  batch:  200 [ 20000/60000]  loss: 0.53042829  accuracy:  81.365%\n",
      "epoch:  1  batch:  400 [ 40000/60000]  loss: 0.39881244  accuracy:  81.933%\n",
      "epoch:  1  batch:  600 [ 60000/60000]  loss: 0.53722703  accuracy:  82.278%\n",
      "epoch:  1  batch:  800 [ 80000/60000]  loss: 0.54923797  accuracy:  82.689%\n",
      "epoch:  1  batch: 1000 [100000/60000]  loss: 0.48998651  accuracy:  82.698%\n",
      "epoch:  1  batch: 1200 [120000/60000]  loss: 0.48812079  accuracy:  82.814%\n",
      "epoch:  1  batch: 1400 [140000/60000]  loss: 0.50622445  accuracy:  82.539%\n",
      "epoch:  1  batch: 1600 [160000/60000]  loss: 0.49494746  accuracy:  82.692%\n",
      "epoch:  1  batch: 1800 [180000/60000]  loss: 0.40856740  accuracy:  82.746%\n",
      "epoch:  1  batch: 2000 [200000/60000]  loss: 0.46552476  accuracy:  82.893%\n",
      "epoch:  1  batch: 2200 [220000/60000]  loss: 0.47703925  accuracy:  82.920%\n",
      "epoch:  1  batch: 2400 [240000/60000]  loss: 0.40019146  accuracy:  82.967%\n",
      "epoch:  1  batch: 2600 [260000/60000]  loss: 0.42995280  accuracy:  83.084%\n",
      "epoch:  1  batch: 2800 [280000/60000]  loss: 0.42867991  accuracy:  83.080%\n",
      "epoch:  1  batch: 3000 [300000/60000]  loss: 0.47333890  accuracy:  83.115%\n",
      "epoch:  1  batch: 3200 [320000/60000]  loss: 0.36052564  accuracy:  83.073%\n",
      "epoch:  1  batch: 3400 [340000/60000]  loss: 0.41812205  accuracy:  83.052%\n",
      "epoch:  1  batch: 3600 [360000/60000]  loss: 0.47746649  accuracy:  83.100%\n",
      "epoch:  1  batch: 3800 [380000/60000]  loss: 0.38671067  accuracy:  83.101%\n",
      "epoch:  1  batch: 4000 [400000/60000]  loss: 0.37709519  accuracy:  83.088%\n",
      "epoch:  1  batch: 4200 [420000/60000]  loss: 0.46946782  accuracy:  83.066%\n",
      "epoch:  1  batch: 4400 [440000/60000]  loss: 0.47802311  accuracy:  83.117%\n",
      "epoch:  1  batch: 4600 [460000/60000]  loss: 0.29809380  accuracy:  83.118%\n",
      "epoch:  1  batch: 4800 [480000/60000]  loss: 0.59079152  accuracy:  83.161%\n",
      "epoch:  1  batch: 5000 [500000/60000]  loss: 0.46632776  accuracy:  83.114%\n",
      "epoch:  1  batch: 5200 [520000/60000]  loss: 0.38991901  accuracy:  83.124%\n",
      "epoch:  1  batch: 5400 [540000/60000]  loss: 0.44245324  accuracy:  83.101%\n",
      "epoch:  1  batch: 5600 [560000/60000]  loss: 0.41672361  accuracy:  83.123%\n",
      "epoch:  1  batch: 5800 [580000/60000]  loss: 0.49213254  accuracy:  83.063%\n",
      "epoch:  1  batch: 6000 [600000/60000]  loss: 0.45100889  accuracy:  83.066%\n",
      "epoch:  1  batch: 6200 [620000/60000]  loss: 0.83998644  accuracy:  82.911%\n",
      "epoch:  1  batch: 6400 [640000/60000]  loss: 0.70946884  accuracy:  82.410%\n",
      "epoch:  1  batch: 6600 [660000/60000]  loss: 0.51926333  accuracy:  81.942%\n",
      "epoch:  1  batch: 6800 [680000/60000]  loss: 0.57273614  accuracy:  81.532%\n",
      "epoch:  1  batch: 7000 [700000/60000]  loss: 0.62862295  accuracy:  81.128%\n",
      "epoch:  1  batch: 7200 [720000/60000]  loss: 0.51150471  accuracy:  80.753%\n",
      "epoch:  1  batch: 7400 [740000/60000]  loss: 0.58421570  accuracy:  80.386%\n",
      "epoch:  1  batch: 7600 [760000/60000]  loss: 0.63088620  accuracy:  80.054%\n",
      "epoch:  1  batch: 7800 [780000/60000]  loss: 0.51106048  accuracy:  79.730%\n",
      "epoch:  1  batch: 8000 [800000/60000]  loss: 0.57144099  accuracy:  79.426%\n",
      "epoch:  1  batch: 8200 [820000/60000]  loss: 0.57427210  accuracy:  79.130%\n",
      "epoch:  1  batch: 8400 [840000/60000]  loss: 0.51314324  accuracy:  78.844%\n",
      "epoch:  1  batch: 8600 [860000/60000]  loss: 0.66817129  accuracy:  78.564%\n",
      "epoch:  1  batch: 8800 [880000/60000]  loss: 0.56144828  accuracy:  78.296%\n",
      "epoch:  1  batch: 9000 [900000/60000]  loss: 0.52334005  accuracy:  78.046%\n",
      "epoch:  1  batch: 9200 [920000/60000]  loss: 0.50313145  accuracy:  77.829%\n",
      "epoch:  2  batch:  200 [ 20000/60000]  loss: 0.49918342  accuracy:  66.700%\n",
      "epoch:  2  batch:  400 [ 40000/60000]  loss: 0.55375499  accuracy:  67.030%\n",
      "epoch:  2  batch:  600 [ 60000/60000]  loss: 0.55929828  accuracy:  67.165%\n",
      "epoch:  2  batch:  800 [ 80000/60000]  loss: 0.59551150  accuracy:  67.270%\n",
      "epoch:  2  batch: 1000 [100000/60000]  loss: 0.56298441  accuracy:  67.237%\n",
      "epoch:  2  batch: 1200 [120000/60000]  loss: 0.48744383  accuracy:  67.282%\n",
      "epoch:  2  batch: 1400 [140000/60000]  loss: 0.56394798  accuracy:  67.218%\n",
      "epoch:  2  batch: 1600 [160000/60000]  loss: 0.51202017  accuracy:  67.215%\n",
      "epoch:  2  batch: 1800 [180000/60000]  loss: 0.55027121  accuracy:  67.272%\n",
      "epoch:  2  batch: 2000 [200000/60000]  loss: 0.51391906  accuracy:  67.290%\n",
      "epoch:  2  batch: 2200 [220000/60000]  loss: 0.52563673  accuracy:  67.355%\n",
      "epoch:  2  batch: 2400 [240000/60000]  loss: 0.57590330  accuracy:  67.377%\n",
      "epoch:  2  batch: 2600 [260000/60000]  loss: 0.59973049  accuracy:  67.382%\n",
      "epoch:  2  batch: 2800 [280000/60000]  loss: 0.45373252  accuracy:  67.401%\n",
      "epoch:  2  batch: 3000 [300000/60000]  loss: 0.53588510  accuracy:  67.421%\n",
      "epoch:  2  batch: 3200 [320000/60000]  loss: 0.63357520  accuracy:  67.435%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2  batch: 3400 [340000/60000]  loss: 0.55093783  accuracy:  67.460%\n",
      "epoch:  2  batch: 3600 [360000/60000]  loss: 0.58512491  accuracy:  67.463%\n",
      "epoch:  2  batch: 3800 [380000/60000]  loss: 0.61356372  accuracy:  67.455%\n",
      "epoch:  2  batch: 4000 [400000/60000]  loss: 0.54848886  accuracy:  67.485%\n",
      "epoch:  2  batch: 4200 [420000/60000]  loss: 0.60005939  accuracy:  67.476%\n",
      "epoch:  2  batch: 4400 [440000/60000]  loss: 0.58648044  accuracy:  67.486%\n",
      "epoch:  2  batch: 4600 [460000/60000]  loss: 0.58387858  accuracy:  67.497%\n",
      "epoch:  2  batch: 4800 [480000/60000]  loss: 0.52861035  accuracy:  67.477%\n",
      "epoch:  2  batch: 5000 [500000/60000]  loss: 0.49742809  accuracy:  67.467%\n",
      "epoch:  2  batch: 5200 [520000/60000]  loss: 0.51303983  accuracy:  67.475%\n",
      "epoch:  2  batch: 5400 [540000/60000]  loss: 0.51829743  accuracy:  67.476%\n",
      "epoch:  2  batch: 5600 [560000/60000]  loss: 0.59066397  accuracy:  67.443%\n",
      "epoch:  2  batch: 5800 [580000/60000]  loss: 0.54300660  accuracy:  67.438%\n",
      "epoch:  2  batch: 6000 [600000/60000]  loss: 0.59822088  accuracy:  67.449%\n",
      "epoch:  2  batch: 6200 [620000/60000]  loss: 0.58641303  accuracy:  67.444%\n",
      "epoch:  2  batch: 6400 [640000/60000]  loss: 0.67682791  accuracy:  67.437%\n",
      "epoch:  2  batch: 6600 [660000/60000]  loss: 0.53797984  accuracy:  67.418%\n",
      "epoch:  2  batch: 6800 [680000/60000]  loss: 0.54699194  accuracy:  67.397%\n",
      "epoch:  2  batch: 7000 [700000/60000]  loss: 0.52062654  accuracy:  67.399%\n",
      "epoch:  2  batch: 7200 [720000/60000]  loss: 0.54812574  accuracy:  67.408%\n",
      "epoch:  2  batch: 7400 [740000/60000]  loss: 0.67830569  accuracy:  67.416%\n",
      "epoch:  2  batch: 7600 [760000/60000]  loss: 0.53898275  accuracy:  67.429%\n",
      "epoch:  2  batch: 7800 [780000/60000]  loss: 0.60847414  accuracy:  67.439%\n",
      "epoch:  2  batch: 8000 [800000/60000]  loss: 0.55432963  accuracy:  67.438%\n",
      "epoch:  2  batch: 8200 [820000/60000]  loss: 0.59911799  accuracy:  67.438%\n",
      "epoch:  2  batch: 8400 [840000/60000]  loss: 0.54228425  accuracy:  67.438%\n",
      "epoch:  2  batch: 8600 [860000/60000]  loss: 0.55574441  accuracy:  67.425%\n",
      "epoch:  2  batch: 8800 [880000/60000]  loss: 0.54071814  accuracy:  67.419%\n",
      "epoch:  2  batch: 9000 [900000/60000]  loss: 0.56527960  accuracy:  67.425%\n",
      "epoch:  2  batch: 9200 [920000/60000]  loss: 0.55526519  accuracy:  67.423%\n",
      "\n",
      "Duration: 55 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 3\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # Here we flatten X_train\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%200 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{100*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(100*b):7.3f}%')\n",
    "    \n",
    "    # Update train loss & accuracy for the epoch\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "    \n",
    "    # Update test loss & accuracy for the epoch\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss at the end of each epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/pyplot.py:2740\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2738\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2741\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/axes/_base.py:496\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    494\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1690\u001b[0m, in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1690\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/branchynet/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1382\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows some evidence of overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data\n",
    "We retained the test scores during our training session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(9439), tensor(9635), tensor(9666), tensor(9726), tensor(9746), tensor(9758), tensor(9737), tensor(9749), tensor(9746), tensor(9725)]\n",
      "\n",
      "Test accuracy: 97.250%\n"
     ]
    }
   ],
   "source": [
    "print(test_correct) # contains the results of all 10 epochs\n",
    "print()\n",
    "print(f'Test accuracy: {test_correct[-1].item()*100/10000:.3f}%') # print the most recent result as a percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to compare the predicted values to the ground truth (the y_test labels), so we'll run the test set through the trained model all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9725/10000 =  97.250%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test.view(len(X_test), -1))  # pass in a flattened view of X_test\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad considering that a random guess gives only 10% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix\n",
    "This uses scikit-learn, and the predicted values obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 968    0    1    0    1    2    5    0    4    1]\n",
      " [   0 1126    4    0    0    0    2    5    0    4]\n",
      " [   2    1 1007    4    3    0    0   10    5    0]\n",
      " [   1    0    5  985    0    2    1    3    4    7]\n",
      " [   1    0    1    0  962    1    3    1    3   12]\n",
      " [   2    1    1   13    0  882   33    1   23   16]\n",
      " [   1    2    2    0    5    1  913    0    1    0]\n",
      " [   1    1    5    5    3    2    0 1003    7    7]\n",
      " [   2    4    6    2    1    2    1    1  925    8]\n",
      " [   2    0    0    1    7    0    0    4    2  954]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the model had the greatest success with ones, twos and sevens, and the lowest with fives, sixes and eights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  61,   62,   81,  104,  115,  151,  193,  217,  247,  259],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [  61   62   81  104  115  151  193  217  247  259  264  320]\n",
      "Label: [   8    9    6    9    4    9    9    6    4    6    9    9]\n",
      "Guess: [   2    5    5    5    9    8    8    5    6    0    4    8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
