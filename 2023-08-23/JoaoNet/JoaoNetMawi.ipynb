{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ca82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=800, out_features=2, bias=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=1152, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.MawiNet import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "model = MawiNetWithExitsCIFAR10()\n",
    "\n",
    "print(model.backbone)\n",
    "print(model.exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef10043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "files = Path('../../datasets/balanced/2019/VIEGAS/XX').iterdir()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file)\n",
    "    df = pd.concat([df, temp])\n",
    "    \n",
    "df = df.drop(['MAWILAB_taxonomy', 'MAWILAB_distance', 'MAWILAB_nbDetectors', 'MAWILAB_label'], axis=1)\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346463/3813123827.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  X_train = torch.FloatTensor(data).view(len(data), 1, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for val in X_train.values:\n",
    "    val = np.append(val, 0).reshape(7,7)\n",
    "    data.append(val)\n",
    "    \n",
    "X_train = torch.FloatTensor(data).view(len(data), 1, 7, 7)\n",
    "y_train = y_train.values\n",
    "\n",
    "data = []\n",
    "for val in X_test.values:\n",
    "    val = np.append(val, 0).reshape(7,7)\n",
    "    data.append(val)\n",
    "    \n",
    "X_test = torch.FloatTensor(data).view(len(data), 1, 7, 7)\n",
    "y_test = y_test.values\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append((X_train[i], y_train[i]))\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    train_data.append((X_test[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0092923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7])\n",
      "torch.Size([1, 1, 7, 7])\n",
      "torch.Size([1, 32, 5, 5])\n",
      "torch.Size([1, 64, 4, 4])\n",
      "torch.Size([1, 128, 3, 3])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    break \n",
    "\n",
    "x = X_train\n",
    "print(x.shape)  \n",
    "x = x.view(1,1,7,7)\n",
    "print(x.shape)\n",
    "x = model.backbone[0](x)\n",
    "print(x.shape)\n",
    "# x = model.exits[0](x)\n",
    "# print(x.shape)\n",
    "x = model.backbone[1](x)\n",
    "print(x.shape)\n",
    "# x = model.exits[1](x)\n",
    "# print(x.shape)\n",
    "\n",
    "x = model.backbone[2](x)\n",
    "print(x.shape)\n",
    "x = model.exits[2](x)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = nn.MaxPool2d(kernel_size=5, stride=2)(x)\n",
    "# print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
